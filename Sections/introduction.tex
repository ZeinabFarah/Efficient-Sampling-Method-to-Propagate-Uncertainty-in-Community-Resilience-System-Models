\section{Introduction}
    \label{sec:intro}    
    In resilience analysis, the actual performance of the system under study cannot be accurately determined due to many uncertain factors, such as intrinsic randomness in material characteristics \cite{padgett_sensitivity_2007}, demand and structural strength \cite{gardoni_life-cycle_2017}, unknown probable infrastructure system failures \cite{woods_managing_2003}, dynamic features of the nearby surroundings \cite{archibald_infrastructure_2013}, and unanticipated human factors \cite{wilson_rail_2005}. Identifying and quantifying these uncertain factors may result in a more realistic assessment of system behavior and associated risks for use in decision-making. It may also provide insight into structured experimentation and learning, which in turn can reduce uncertainties \cite{allen_adaptive_2011}. \\
    One technique to study the impact of uncertain factors on models is called \textbf{\textit{uncertainty propagation}} which is the quantification of the output uncertainty that results from the input uncertainty \cite{morgan_uncertainty_1992}. At the simplest level, uncertainty propagation can be viewed as the study of functions of the form $y=f(x)$, where the function $f$ represents the model or models under study, $x=[x_1,x_2,…]$ is a vector of model inputs, and $y=[y_1,y_2,…]$ is a vector of model outputs. The goal of uncertainty propagation is to determine the uncertainty in the elements of $y$ that results from uncertainty in the elements of $x$.\\
    Various techniques have been used in the literature for uncertainty propagation in resilience analysis, with simulation being the most popular one \cite{sun_resilience_2020}. A comprehensive review of the uncertainty propagation methods in resilience analysis can be found in \cite{sun_resilience_2020}. In particular, Monte Carlo (MC) is a simulation method that has been widely used \cite{zheng_bayesian-based_2022, cicilio_electrical_2020, tabandeh_uncertainty_2022, younesi_assessing_2020} for uncertainty propagation by generating random samples from a defined input domain, like a set of probability density functions. \\ 
    MC methods are particularly desirable when the function $f$ depends on numerous random variables since they are simple to construct and maintain computational tractability. But when it comes to rare events with small probabilities, like natural disasters, the sampling error in MC estimates could have a big effect on the results. Although employing additional samples in the MC procedure can lower the sampling error in MC estimates, this method is not computationally tractable since each sample necessitates the solution of a different problem. As a result, to obtain MC estimates with lower sampling error for a moderate number of samples, it has to be used in conjunction with a variance reduction technique. One of the well-known techniques for reducing variance is the importance sampling technique, which aims to estimate quantities accurately while using fewer samples than necessary for the Monte Carlo method. \\
    It should be noted that the term "variance reduction" refers to the reduction of estimate variance, i.e., the variance of the estimator or model uncertainty, and not the variance inherited from uncertainties in system parameters. In general, if more information about the system parameters is added, the variation caused by parameter uncertainty can be reduced. The estimator's variance can also be reduced by using a good estimator (such as importance sampling) so that the estimator converges to the true value more quickly.\\
    With this background in mind, this work compares the computational performance of Monte Carlo versus importance sampling methods for reliability analysis (calculation of failure probability in meeting the expected demands) of a water distribution network. Importance sampling is typically an effective technique in reliability analysis that can be used to estimate small failure probabilities \cite{melchers_importance_1989, heinkenschloss_conditional-value-at-risk_2018}. Even though importance sampling-based approaches can improve the effectiveness of probability of failure estimation if the importance density function is not created properly, the estimate may still require a large number of samples. To address this issue, a number of effective adaptive importance sampling techniques that iteratively approach the optimal importance density function have been developed \cite{tomasson_improved_2017, depina_coupling_2017, ching_efficient_2009, chaudhuri_information_2020, aslam_ansari_data-driven_2020}. \\
    The application of an adaptive IS technique called Markov-Chain Monte Carlo Importance Sampling (MCMC-IS) in comparison with crude Monte Carlo is demonstrated in this paper. The rest of the paper is structured as follows: Section 2 provides a brief overview of uncertainty analysis, followed by an overview of the literature using Monte Carlo methods for uncertainty analysis in the risk and resilience assessment area. Section 3 explains the importance sampling techniques and their mathematical representation, and MCMC-IS is introduced as a special type of adaptive IS technique. In Section 4, the application of the MCMC-IS is demonstrated on a one-dimensional example, and Section 5 compares the performances of crude Monte Carlo and the MCMC-IS to determine the reliability of two water distribution networks. Finally, concluding remarks are given in Section 6.

